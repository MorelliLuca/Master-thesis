\label{chap:constr}
\markboth{\textbf{Chapter 9.  Constraints from B-modes and forecast for future experiments}}{\emph{\nouppercase{\rightmark}}}
Current non-detection of CMB spectral distortions puts constraints on their allowed amplitudes: for example, COBE/FIRAS \cite{COBE1996} sensitivity resulted in the following upper limits 
\begin{equation}\label{eq:cobe7firas_sens}
    |\mu|<9\times10^{-5}, \qquad  |y|<1.5\times 10^{-5}.
\end{equation}
Moreover, considering the specifications of proposed space missions that aim to detect for the first time spectral distortions, such as PIXIE \cite{pixie,A_Kogut_2011,Chluba_2021} or FOSSIL \cite{IAS_Fossil}, we can produce forecasts for the future. In the following section we will consider the PIXIE sensitivity \cite{Chluba_2021}
\begin{equation}
    \label{eq:pix_sens} \delta\mathcal I_\text{PIXIE}\approx2 \text{Jr/Sr},
\end{equation}
which should allow for a detection of $\mu$-distortions at the level of $\sigma_\text{PIXIE} (\mu)\sim 2\times10^{-8}$ at 68 \% CL. 
Note that such sensitivity is insufficient to detect tensor-induced spectral distortions for a nearly scale-invariant spectrum as predicted by the simplest models of inflation, which are at the level of $\mu \sim 10^{-14}$.

%Primordial gravitational waves also lack of a detection of a cosmological signal, for example from the B-modes of polarization anisotropies of the CMB, which are sourced only by primordial gravitational waves. 
We have not detected primordial gravitational waves yet and we have only upper limits. By using CMB B-mode polarization, BICEP/\textit{Keck} 2018 \cite{Ade_2021} set a limit to the tensor-to-scalar ratio at $k_\star=0.05$ Mpc$^{-1}$ as $r<0.035$ at $95\%$ CL. Further constraints have been obtained by Paoletti et al. \cite{Paoletti_2022} by relaxing the consistency relation $n_t=-r/8$, by adopting a two-scale parametrization for a power-law spectrum (see  Section \ref{sec:primordial_PS}) $k_1=0.005$ and $k_2=0.02$ and including also \textit{Planck} 2018 data \cite{Planck:2019nip}:
\begin{equation}
    r_{0.005}<0.030,\quad r_{0.02}<0.098\qquad\text{at 95\% CL.}
\end{equation}
These limits update those obtained by the Planck collaboration \cite{Planck:2015sxf,Planck:2018jri}.

Spectral distortions generated by the dissipation of primordial gravitational waves can be used to further constraint the tensor primordial power spectrum. In this chapter, we will study for the first time which constraints can be put on such spectrum by future spectral distortions space missions. We will use both data from BICEP/\textit{Keck} 2018 and simulated data from a PIXIE-like experiment to constrain a power-law spectrum of primordial gravitational waves.
%study how spectral distortions can impact constraints on the tensor-to-scalar ratio. 
We will then study the constraints on log-normal templates (superimposed on the gravitational waves produced in the simplest models) placed at the spectral distortion scales with only the PIXIE-like simulated data.

\section{Methodology of the analysis}
Modern cosmology relies heavily on numerical tools, mainly for the complexity of the different equations that must be solved altogether: for example the Boltzmann hierarchy, which in theory is composed of an infinite number of equation (each multipole) for each component of the plasma.
To produce numerical results two publicly available codes has been used: the first one is \textbf{\texttt{CLASS}} (Cosmic Linear Anisotropies Solving System) \cite{CLASS}, which is an Einstein-Boltzmann solver which computes also the amplitude of spectral distortions for several injecting phenomena, and then \textbf{\texttt{MontePython}} \cite{Brinckmann:2018cvx,Audren:2012wb}, which in combination with \texttt{CLASS} allows inferring constraints using \emph{Monte Carlo Markov Chains} algorithms.

Before proceeding discussing the results of our analysis, we are going to explain the main modifications we apported to \texttt{CLASS} and we will also give a little of background on \textit{Bayesian inference} and \textit{MCMC} analysis.
\subsection{Modifications to \texttt{CLASS}}
To allow \texttt{MontePython} to work with tensor-induced spectral distortions, we developed a modified version of \texttt{CLASS} which computes also the heating rates we derived in Section \ref{sec:dissipation_PGW}. Our implementation takes into account how the different transfer functions change during the matter-radiation domination transition, allowing for a more accurate computation of amplitudes using the Green's function method (see Section \ref{sec:branching_ratios}. Note that our implementation, also allows for modifications of the heating rate or of the background evolution to be included, and for MCMC analysis to be conducted with tensor generated spectral distortions, which are thing that previously available codes (i.e. the one presented in \cite{Kite_2021}) were not capable to do.\\
To adapt \texttt{CLASS} to our needs we included two more modifications: first we allowed also the tensor primordial power spectrum to be parameterized using the \emph{2 scales} formalism, 
$$\mathcal P_T(k)=\exp\bigg\{\frac{\log k-\log k_1}{\log k_1 -\log k_2}\log \Big[r_{k_2}\mathcal{P_R}(k_2)\Big]-\frac{\log k-\log k_2}{\log k_1 -\log k_2}\log \Big[r_{k_1}\mathcal{ P_{R}}(k_1)\Big]\bigg\},$$
 then we also introduced the possibility of adding \emph{log-normal} bumps on top of the power law power spectrum.
\subsection{Bayesian inference and MCMC algorithms}
Observations constraint any theoretical model since any observed data must be reproducible by the model. To prove this compatibility a Bayesian approach can be used: consider a model $\theta=\{\theta_1,\theta_2,\dots\theta_n\}$, where $\theta_i$ are the parameters of the model, and a set of observed data $d$, we can then estimate the probability that our model is right given the observed data by the \emph{Bayes theorem}
\begin{equation}
    P(\theta|d)=\frac{P(d|\theta)P(\theta)}{P(d)},
\end{equation}
where $P(\theta|d)$ is called the \textbf{posterior distribution}. $\pi(\theta)\defeq P(\theta)$ is known as the \textbf{prior distribution} and it represents our knowledge on the parameters of the model, prior to any observation, and usually is taken to be a uniform or Gaussian distribution.  $\mathcal{L}(\theta)\defeq P(d|\theta)$ is called \textbf{likelihood function} and it represents the probability of obtaining the observed data from the model. Lastly, $P(d)$ is known as the \textbf{evidence}, which is less relevant for our discussion since it effectively only normalizes the posterior to 1, 
$$P(d)=\int d^n\theta\ \mathcal{L}(\theta)\pi(\theta)=\int d^n\theta\ P(d|\theta)P(\theta).$$
In this way the problem of finding the posterior distribution is reduced to the problem of determining the probability that our theoretical model produces the observed data. Note that assuming a uniform prior the posterior becomes directly proportional to the likelihood.\\ 
Once we obtained the posterior distribution, it is possible to \emph{marginalize} it to find the distribution of the $i$-th parameter of the assumed theoretical model, namely by integrating over the configuration space of the remaining parameters
$$P(\theta_i|d)\propto\int d\theta_1\dots d\theta_{i-1}d\theta_{i+1}\dots d\theta_n\ P(\theta|d). $$

To obtain the posterior distribution, due to the complexity of the likelihood functions $\mathcal L(\theta)$ and the high number of parameters that can be considered, numerical algorithms that explore the parameter space of $\theta$ are used. Monte Carlo Markov Chains represent a class of these algorithms that, given a probability distribution, generates \textbf{Markov chains}\footnote{A Markov chain is a sequence of statistical events in which the probability associated to each element of the chain depends only on the state of the previous event.} of the parameters of the theoretical model which density is proportional to the posterior distribution itself. In this way, once each chain reached a \emph{stationary state} the chain itself can be used as an ensemble determined by the posterior.\\
Each chain is generated by a random walk in the parameter space of the model which is determined by the \textbf{transition probability} $T\big(\theta^{(t)},\theta^{(t+1)}\big)$, between the points $\theta^{(t)}$ and $\theta^{(t+1)}$. The transition probability is determined by imposing the \emph{detailed balance condition}
$$\frac{T\big(\theta^{(t)},\theta^{(t+1)}\big)}{T\big(\theta^{(t+1)},\theta^{(t)}\big)}=\frac{P\big(\theta^{(t+1)}|d\big)}{P\big(\theta^{(t)}|d\big)}.$$
Then, statistical averages can be approximated using the elements of each chain
$$E[f(\theta)]=\int d^n\theta\ f(\theta)P(\theta|d)\approx\frac1M\sum_{t=0}^{M-1}f\big(\theta^{(t)}\big),$$
where $\theta^{(t)}$ is the $t$-th element of the chain. Similarly, the marginalized distributions can be obtained considering only a subset of parameters, discretizing their domains in bins and counting how main points of the chain fall in each bin.

We conclude this section presenting one of the simplest MCMC algorithms, the \emph{Metropolis-Hastings} algorithm, which is also the algorithm we used. This algorithm start from a initial guess point $\theta^{(0)}$ and randomly generates a candidate for the next point in the chain $\theta^{(c)}$ drawn from an arbitrary distribution $q\big(\theta^{(0)},\theta^{(c)}\big)$. Then the algorithm decides whether to discard the proposed candidate or to accept it as the next element of the chain: this is done by generating a random number $\mu\in[0,1)$ and the using the following criterion
\begin{equation}
    \theta^{(c)}\text{ accepted if }\mu<\min\Bigg(\frac{P\big(\theta^{(c)}|d\big)q\big(\theta^{(c)}|\theta^{(0)}\big)}{P\big(\theta^{(0)}|d\big)q\big(\theta^{(0)}|\theta^{(c)}\big)}\Bigg),\text{ otherwise rejected.}
\end{equation}
If the candidate is rejected a new point is generated, otherwise the chain continues repeating this algorithm substituting the point $\theta^{(0)}$ with the previous element of the chain.
\subsection{Spectral distortion likelihood and foreground}
To perform a Bayesian analysis using data from CMB observations or using simulated data, it is necessary to define an appropriate likelihood function. In our case of interest, the likelihood should take into account the outcome of CMB spectral distortion measurements and compare it with the theoretical prediction of our proposed models. Starting from the cosmological parameters obtained from the Planck \emph{TT,TE,EE + lowE + lensing data} \cite{planck2018results}, \texttt{CLASS} computes the fiducial values of the distortions, which represent the simulated observation. Then, each set of parameters of each chain which is produced is compared with the fiducial distortion by the following likelihood function
\begin{equation}
    \log \mathcal L\defeq -\frac12 \sum_{\nu \text{ bins }}\bigg(\frac{\Delta\mathcal I_\text{obs}(\nu_i)-\Delta\mathcal I_\text{fid}(\nu_i)}{\delta \mathcal I(\nu_i)}\bigg)^2,
\end{equation}
where $\nu_i$ is the $i$-th frequency bin of the assumed detector and $\delta \mathcal I(\nu_i)$ the corresponding sensitivity. $\Delta \mathcal I(\nu_i)$ is instead the spectral distortion itself, which can be the result of the superposition of different distortions due to different effects. 

The first effect we should account for is any eventual error in the measurement of the CMB temperature monopole, namely the average temperature of the CMB. Indeed, any small error can be modeled as a small shift in temperature $\Delta T$, which as we showed in Section \ref{sec:SD_shapes} corresponds to a spectral distortion.

Moreover, the Zeldovich-Sunayev effect \cite{Zeldovich1972} can produce a $y$-distortion by the interaction of the CMB photons with the reionized electrons of the \emph{intracluster medium} or the \emph{intergalactic medium}. These scatterings, taking place in the late universe, will inject energy in the decoupled CMB which then is not able to thermalize, producing a $y$-distortion:
$$ \Delta \mathcal I_{ZS}(x)=(k_BT_z)^3x^3 y_\text{reio} Y(x),$$
where we used the definitions of Section \ref{sec:ThermalizationProblem}.

Lastly, a \emph{foreground} can be produced as the result of many processes, such as \emph{Galactic thermal dust}, the \emph{Cosmic Infrared Background} (CIB), the \emph{synchrotron}, \emph{free-free, spinning dust} and \emph{integrated CO emission}. As explained in \cite{constraininginflationarypotentialspectral} this foreground can be modeled as the superposition of the following components
\begin{align}
    &\Delta \mathcal I_i(x)=A_i\bigg(\frac{x_i}{x_{\text{ref}}}\bigg)^{\beta_i+3} \frac{e^{x_{\text{ref}}}-1}{e^{x_i}-1},\qquad\qquad\text{with } x_i\defeq\frac{\nu}{k_BT_i}\text{ and } \nu_\text{ref}=545\text{GHz},\label{eq:FOR_i}\\
    &\Delta \mathcal{I}_\text{sync} (x)= A_S\bigg(\frac{x_\text{ref}}{x}\bigg)^{\alpha_S+\tfrac{\omega_S}2\log^2(x/x_\text{ref})}\qquad \text{with }\nu_\text{ref}=100\text{GHz},\label{eq:FOR_sync}\\\nonumber
    &\Delta \mathcal{I}_\text{free-free}(x)= A_\text{ff} \mathcal{ N} T_e\big(1-e^{-\tau_{\text{ff}}}\big),&\\
    &\qquad\qquad\tau_\text{ff}\approx 0.05468\text{EM}\bigg(\frac{T_e}{\text{K}}\bigg)^{-3/2}\bigg(\frac{\nu}{\text{GHz}}\bigg)^{-2}g_\text{ff},& \\ &\qquad\qquad g_\text{ff}\approx \log\bigg\{ e+\exp\bigg[5.96-\frac{\sqrt{3}}{\pi}\log\bigg(\frac{\nu}{\text{GHz}}\Big(\frac{T_e}{10^4\text{K}}\Big)^{-3/2}\bigg)\bigg]\bigg\},\nonumber
\end{align}  
where in the first equation $i$ can be either \emph{thermal dust} or \emph{CIB} and $x$ is the dimensionless frequency as defined in Section \ref{sec:ThermalizationProblem}. Spinning dust and CO emissions are instead modeled using particular templates following \cite{refId0,10.1093/mnras/stx1653}.

Overall, the following 16 nuisance parameters regulate the distortion signal that we should remove to obtain only the cosmological spectral distortions.
\begin{table}[ht!]
\centering
\begin{tabular}{ c p{12cm} }
\hline
\textbf{Parameter} & \textbf{Description} \\
\hline
$\Delta T$      & Temperature shift amplitude \\
$T_D$           & Temperature of thermal dust \\
$\beta_D$       & Tilt of the power law in Equation \eqref{eq:FOR_i} in the case of thermal dust\\
$A_D$           & Amplitude of the spectral distortion (SD) due to thermal dust \\
$T_{\text{CIB}}$& Cosmic Infrared Background (CIB) temperature \\
$\beta_{\text{CIB}}$ & Tilt of the power law in equation \eqref{eq:FOR_i} in the case of CIB \\
$A_{\text{CIB}}$ & Amplitude of the SD due to CIB \\
$\alpha_{\text{sync}}$ & Exponent appearing in Equation \eqref{eq:FOR_sync} \\
$\omega_{\text{sync}}$ & Exponent appearing in Equation \eqref{eq:FOR_sync} \\
$A_{\text{sync}}$ & Amplitude of the SD due to synchrotron emission \\
$T_e$           & Temperature of electron plasma \\
$\mathrm{EM}$   & Emission measure in the free-free emission \\
$\nu_{\text{spin}}$ & Parameter for the shape of the distortion due to spinning dust \\
$A_{\text{spin}}$ & Amplitude of the SD due to spinning dust \\
$A_{\text{CO}}$ & Amplitude of the SD due to CO emission \\
$y_\text{reio}$ & Amplitude of the y-distortion due to reonization.\\
\hline
\end{tabular}
\caption{Nuisance parameters describing the foreground of PXIE-like experiments.}
\label{tab:nui_pixie}
\end{table}
\subsection{Semi-analytical constraints}
Before moving on to the analysis of the constraints obtained by Bayesian inference, we should indicate that also a semi-analytical approach can be used to constraint the power spectrum of primordial gravitational waves. The main idea behind this method is that for each wave number we can find the threshold value of the power spectrum, for which we would meet the sensitivity of some experiment. Recalling the construction of the window function \eqref{eq:window_function}
$$a=\int dk\ \mathcal P_T(k) W_a(k),$$
we can use a Dirac delta power spectrum, which basically corresponds to the assumption that the whole distortion is sourced by the dissipation of just one single wave number. 
\begin{figure}[h]
    \centering
\begin{tikzpicture}
  \begin{axis}[
      grid=major,
      xlabel={$k$ [1/Mpc]},
      ylabel={$\mathcal{P}_T$},
      width=10cm, height=7cm,
      xmode = log, ymode = log,
      xmin = 1e-7, xmax = 1e11,
      %ymin = 1e-11, ymax = 1e3,
      legend pos = north east,
      legend style={font=\scriptsize},
  ]
    % Load and plot from the external file
    \addplot [thick, smooth] table {Constraints/constr_PIXIE_mu.dat};
    \addlegendentry{PIXIE semi-analytical constraint}
    \addplot [thick, smooth, gray] table {Constraints/constr_FIRAS_mu.dat};
    \addlegendentry{FIRAS semi-analytical constraint}
  \end{axis}
\end{tikzpicture}
\caption{Comparison of  the semi-analytical constraints given by PIXIE and FIRAS.}
\label{fig:analy_const}
\end{figure}
Requiring that the resulting distortion meets the sensitivity of the considered experiment,
$$\mathcal P(k)\defeq A_\delta\ \delta\bigg(\log\frac{k}{\hat k}\bigg)\quad \Rightarrow\quad A_\delta W_a\big(\hat k\big)<a_{\text{sens}}\quad \Rightarrow\quad A_{\text{sens}}(k)=\frac{a_{\text{sens}}}{W_a(k)},$$
we obtain the maximum allowed amplitude for the power spectrum at the scale $\hat k$. Combining all the amplitudes obtained, we are constructing a function which indicates the maximum allowed values of the power spectrum given a non detection of the distortions. 

For example, in Figure \ref{fig:analy_const} we plot and compare the semi-analytical constraints set both by COBE/FIRAS and by the forecast on PIXIE. To produce this plot we used the claimed PIXIE sensibility $\sigma_\mu=4\times10^{-8}$ at 68\% CL \cite{Chluba_2021} and the sensibility \eqref{eq:cobe7firas_sens}}. 


