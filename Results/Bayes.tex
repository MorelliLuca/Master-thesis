The effects of the dissipation of primordial perturbations we described must meet current observations of the CMB. For example, the observed absence of spectral distortions by COBE/FIRAS \cite{COBE1996} constraints the possible amplitudes to 
\begin{equation}
    |\mu|<9\times10^{-5},\quadd  |y|<1.5\times 10^{-5}.
\end{equation}
Moreover, considering the design of proposed future missions that aims to detect for the first time spectral distortions, such as PIXIE \cite{pixie}, we can produce forecasts on the expected amplitudes of spectral distortions.
\section{Methodology of the analysis}
To produce numerical results two publicly available codes has been used: first \textbf{CLASS} (Cosmic Linear Anisotropies Solving System) \cite{CLASS}, which is an Einstein-Boltzmann solver which computes also the amplitude of spectral distortions for several injecting phenomena, and then \textbf{MontePython} \cite{Brinckmann:2018cvx,Audren:2012wb}, which in combination with CLASS allows to infer constraints using \emph{Monte Carlo Markov Chains} algorithms.\\
To use these two tools to analyze spectral distortions sourced by primordial gravitational waves, we developed a modified version of CLASS which computes also the heating rates we derived in Section \ref{sec:dissipation_PGW}. 

Before proceeding discussing the results of our analysis, we are going to explain how the analysis has been conducted.
\subsection{Bayesian inference and MCMC algorithms}
Observations constraint any theoretical model since any observed data must be reproducible by the model. To prove this compatibility a Bayesian approach can be used: consider a model $\theta=\{\theta_1,\theta_2,\dots\theta_n\}$, where $\theta_i$ are the parameters of the model, and and a set of observed data $d$, we can then estimate the probability that our model is right given the observed data by the \emph{Bayes theorem}
\begin{equation}
    P(\theta|d)=\frac{P(d|\theta)P(\theta)}{P(d)},
\end{equation}
where $P(\theta|d)$ is called the \textbf{posterior distribution}. $\pi(\theta)\defeq P(\theta)$ is known as the \textbf{prior distribution} and it represents our knowledge on the parameters of the model, prior to any observation, and usually is taken to be a uniform or gaussian distribution.  $\mathcal{L}(\theta)\defeq P(d|\theta)$ is called \textbf{likelihood function} and instead it represents the probability of obtaining the observed data from the model. Lastly, $P(d)$ is known as the \textbf{evidence}, which is less relevant for our discussion since it effectively only normalizes the posterior to 1, 
$$P(d)=\int d^n\theta\ \mathcal{L}(\theta)\pi(\theta)=\int d^n\theta\ P(d|\theta)P(\theta).$$
In this way the problem of finding the posterior distribution is reduced to the problem of determining the probability that our theoretical model produces the observed data. Note that assuming a a uniform prior the posterior becomes directly proportional to the likelihood.\\ 
Once we obtained the posterior distribution, it is possible to \emph{marginalize} it to find the distribution of the $i$-th parameter of the assumed theoretical model, namely by integrating over the configuration space of the remaining parameters.
$$P(\theta_i|d)\propto\int d\theta_1\dots d\theta_{i-1}d\theta_{i+1}\dots d\theta_n\ P(\theta|d). $$

To obtain the posterior distribution, due to the complexity of the likelihood functions $\mathcal L(\theta)$ and the high number of parameters that ca be considered, numerical algorithms that explore the parameter space of $\theta$ are used. Monte Carlo Markov Chains is a class of these algorithm that, given a probability distribution, generates \textbf{Markov chains}\footnote{A Markov chain is a sequence of statistical events in which the probability associated to each element of the chain depends only on the state of the previous event.} of the parameters of the theoretical model which density is proportional to the posterior distribution itself. In this way, once each chain reached a \emph{stationary state} the chain itself can be used as an ensemble determined by the posterior.\\
Each chain is generated by a random walk in the parameter space of the model which is determined by the \textbf{transition probability} $T\big(\theta^{(t)},\theta^{(t+1)}\big)$, between the points $\theta^{(t)}$ and $\theta^{(t+1)}$. The transition probability is determined by imposing the \emph{detailed balance condition}
$$\frac{T\big(\theta^{(t)},\theta^{(t+1)}\big)}{T\big(\theta^{(t+1)},\theta^{(t)}\big)}=\frac{P\big(\theta^{(t+1)}|d\big)}{P\big(\theta^{(t)}|d\big)}.$$
Then, statistical averages can be approximated using the elements of each chain
$$E[f(\theta)]=\int d^n\theta\ f(\theta)P(\theta|d)\approx\frac1M\sum_{t=0}^{M-1}f\big(\theta^{(t)}\big),$$
where $\theta^{(t)}$ is the $t$-th element of the chain. Similarly, the marginalized distributions can be obtained considering only a subset of parameters, discretizing their domains in bins and counting how main points of the chain fall in each bin.

We conclude this section presenting one of the simplest MCMC algorithms, the \emph{Metropolis-Hastings} algorithm. This algorithm start from a initial guess point $\theta^{(0)}$ and randomly generates a candidate for the next point in the chain $\theta^{(c)}$ drawn from an arbitrary distribution $q\big(\theta^{(0)},\theta^{(c)}\big)$. Then the algorithm decides whether to discard the proposed candidate or to accept it as the next element of the chain: this is done by generating a random number $\mu\in[0,1)$ and the using the following criterion
\begin{equation}
    \theta^{(c)}\text{ accepted if }\mu<\min\Bigg(\frac{P\big(\theta^{(c)}|d\big)q\big(\theta^{(c)}|\theta^{(0)}\big)}{P\big(\theta^{(0)}|d\big)q\big(\theta^{(0)}|\theta^{(c)}\big)}\Bigg),\text{ otherwise rejected.}
\end{equation}
If the candidate is rejected a new point is generated, otherwise the chain continues repeating this algorithm substituting the point $\theta^{(0)}$ with the previous element of the chain.
\subsection{CMB likelihoods}



